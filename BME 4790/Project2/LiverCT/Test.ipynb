{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "0",
   "source": [
    "# Model Evaluation - Confusion Matrix\n",
    "Evaluates the trained 3D U-Net model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "1",
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "2",
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Define Loss Functions (needed for model loading)\n",
    "# =============================================================================\n",
    "\n",
    "CLASS_WEIGHTS = [0.1, 1, 20.0]\n",
    "\n",
    "def dice_coefficient_per_class(y_true, y_pred, class_idx):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_true_c = y_true[..., class_idx]\n",
    "    y_pred_c = y_pred[..., class_idx]\n",
    "    y_true_f = tf.keras.backend.flatten(y_true_c)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred_c)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f))\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    total_loss = 0.0\n",
    "    for class_idx, weight in enumerate(CLASS_WEIGHTS):\n",
    "        dice = dice_coefficient_per_class(y_true, y_pred, class_idx)\n",
    "        total_loss += weight * (1 - dice)\n",
    "    return total_loss / sum(CLASS_WEIGHTS)\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f))\n",
    "\n",
    "def dice_liver(y_true, y_pred):\n",
    "    return dice_coefficient_per_class(y_true, y_pred, 1)\n",
    "\n",
    "def dice_tumor(y_true, y_pred):\n",
    "    return dice_coefficient_per_class(y_true, y_pred, 2)\n",
    "\n",
    "print(\"Loss functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "3",
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Setup Test Files\n",
    "# =============================================================================\n",
    "\n",
    "DATA_DIR = 'preprocessed_patches_v2'\n",
    "NUM_CLASSES = 3\n",
    "SEED = 42\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# Get test files (same split as training)\n",
    "all_files = sorted([os.path.join(DATA_DIR, f) for f in os.listdir(DATA_DIR) if f.endswith('.npz')])\n",
    "np.random.seed(SEED)\n",
    "indices = np.random.permutation(len(all_files))\n",
    "train_end = int(len(all_files) * 0.70)\n",
    "val_end = train_end + int(len(all_files) * 0.15)\n",
    "test_files = [all_files[i] for i in indices[val_end:]]\n",
    "\n",
    "print(f\"Total files: {len(all_files)}\")\n",
    "print(f\"Test set: {len(test_files)} files ({len(test_files) * 20} patches)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "4",
   "outputs": [],
   "source": "# =============================================================================\n# Load Best Model + Warmup\n# =============================================================================\n\nMODEL_PATH = 'checkpoints/best_model.keras'\n\nprint(f\"Loading model from {MODEL_PATH}...\")\nmodel = tf.keras.models.load_model(\n    MODEL_PATH,\n    custom_objects={\n        'weighted_dice_loss': weighted_dice_loss,\n        'dice_coefficient': dice_coefficient,\n        'dice_liver': dice_liver,\n        'dice_tumor': dice_tumor\n    }\n)\nprint(\"Model loaded successfully!\")\nprint(f\"Model parameters: {model.count_params():,}\")\n\n# Warmup prediction to trigger XLA compilation (this takes 1-2 minutes)\nprint(\"\\nWarming up model (XLA compilation - this takes 1-2 min)...\")\nwarmup_start = time.time()\ndummy_input = np.zeros((1, 128, 128, 128, 1), dtype=np.float32)\n_ = model.predict(dummy_input, verbose=0)\nprint(f\"Warmup done in {time.time()-warmup_start:.1f}s - ready for evaluation!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "5",
   "outputs": [],
   "source": "# =============================================================================\n# Compute Confusion Matrix\n# =============================================================================\n\nprint(\"Computing confusion matrix on test set...\")\nprint(f\"Processing {len(test_files)} files ({len(test_files)*20} patches)...\\n\")\n\ncm = np.zeros((NUM_CLASSES, NUM_CLASSES), dtype=np.int64)\ntotal_patches = 0\nstart_time = time.time()\n\nfor file_idx, filepath in enumerate(test_files):\n    file_start = time.time()\n    data = np.load(filepath)\n    patches = data['patches'].astype(np.float32) / 255.0\n    segs = data['segmentations']\n    \n    # Process in batches\n    for i in range(0, len(patches), BATCH_SIZE):\n        x = patches[i:i+BATCH_SIZE][..., np.newaxis]\n        y_true = segs[i:i+BATCH_SIZE]\n        \n        pred = model.predict(x, verbose=0)\n        y_pred = np.argmax(pred, axis=-1)\n        \n        # Accumulate confusion matrix\n        cm += confusion_matrix(y_true.flatten(), y_pred.flatten(), labels=[0, 1, 2])\n        total_patches += len(x)\n    \n    file_time = time.time() - file_start\n    total_time = time.time() - start_time\n    eta = (total_time / (file_idx + 1)) * (len(test_files) - file_idx - 1)\n    print(f\"  [{file_idx+1:2d}/{len(test_files)}] {os.path.basename(filepath)}: {file_time:.1f}s (ETA: {eta:.0f}s)\")\n\nprint(f\"\\n{'='*50}\")\nprint(f\"DONE! Total time: {time.time()-start_time:.1f}s\")\nprint(f\"Total voxels evaluated: {cm.sum():,}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "6",
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Plot Confusion Matrix\n",
    "# =============================================================================\n",
    "\n",
    "class_names = ['Background', 'Liver', 'Tumor']\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True) * 100\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Raw counts\n",
    "im1 = axes[0].imshow(cm, cmap='Blues')\n",
    "axes[0].set_title('Confusion Matrix (Counts)', fontsize=14)\n",
    "axes[0].set_xlabel('Predicted', fontsize=12)\n",
    "axes[0].set_ylabel('True', fontsize=12)\n",
    "axes[0].set_xticks(range(3))\n",
    "axes[0].set_yticks(range(3))\n",
    "axes[0].set_xticklabels(class_names)\n",
    "axes[0].set_yticklabels(class_names)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axes[0].text(j, i, f'{cm[i,j]:,}', ha='center', va='center', fontsize=10)\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Normalized (percentages)\n",
    "im2 = axes[1].imshow(cm_norm, cmap='Blues', vmin=0, vmax=100)\n",
    "axes[1].set_title('Confusion Matrix (% by True Class)', fontsize=14)\n",
    "axes[1].set_xlabel('Predicted', fontsize=12)\n",
    "axes[1].set_ylabel('True', fontsize=12)\n",
    "axes[1].set_xticks(range(3))\n",
    "axes[1].set_yticks(range(3))\n",
    "axes[1].set_xticklabels(class_names)\n",
    "axes[1].set_yticklabels(class_names)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axes[1].text(j, i, f'{cm_norm[i,j]:.1f}%', ha='center', va='center', fontsize=10)\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConfusion matrix saved to confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "7",
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Print Per-Class Metrics\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PER-CLASS METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Class':<12} {'Precision':>10} {'Recall':>10} {'F1':>10} {'Dice':>10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for i, name in enumerate(class_names):\n",
    "    tp = cm[i, i]\n",
    "    fp = cm[:, i].sum() - tp\n",
    "    fn = cm[i, :].sum() - tp\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    dice = (2 * tp) / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0\n",
    "    \n",
    "    print(f\"{name:<12} {precision:>10.4f} {recall:>10.4f} {f1:>10.4f} {dice:>10.4f}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Overall accuracy\n",
    "accuracy = np.trace(cm) / cm.sum()\n",
    "print(f\"\\nOverall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}