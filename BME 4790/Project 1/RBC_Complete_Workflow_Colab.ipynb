{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBC Classification - Complete Workflow (Grayscale)\n",
    "This notebook uses grayscale images to reduce training time and inverted segmentation.\n",
    "\n",
    "## Workflow Steps:\n",
    "1. **Setup & Configuration** - Import libraries and set parameters\n",
    "2. **Data Preparation** - Load, preprocess (grayscale), and split image data\n",
    "3. **Model Definition** - Build CNN and baseline models\n",
    "4. **Training** - Train models and visualize learning curves\n",
    "5. **Evaluation** - Test models and generate reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Parameters\n",
    "\n",
    "# Data preparation parameters\n",
    "DATASET_DIR = \"bloodcells_dataset\"  # Change this to your dataset path\n",
    "IMG_SIZE = 224\n",
    "VAL_FRAC = 0.15\n",
    "TEST_FRAC = 0.15\n",
    "LIMIT_PER_CLASS = None  # Set to a number to limit images per class\n",
    "SEGMENTATION_THRESHOLD = 0.3  # Pixels ABOVE this will be set to zero (inverted)\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Output paths\n",
    "OUT_DIR = \"./artifacts_grey\"\n",
    "OUT_NPZ = os.path.join(OUT_DIR, \"rbc_data_grey.npz\")\n",
    "\n",
    "# Create output directories\n",
    "for d in [OUT_DIR, f\"{OUT_DIR}/models\", f\"{OUT_DIR}/plots\", f\"{OUT_DIR}/reports\"]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(f\"Dataset directory: {os.path.abspath(DATASET_DIR)}\")\n",
    "print(f\"Output directory: {os.path.abspath(OUT_DIR)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image file extensions\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
    "\n",
    "def get_class_names(dataset_dir: str) -> List[str]:\n",
    "    \"\"\"Get sorted list of class names from dataset directory.\"\"\"\n",
    "    names = [d.name for d in Path(dataset_dir).iterdir() if d.is_dir()]\n",
    "    names = sorted(names)\n",
    "    if not names:\n",
    "        raise ValueError(f\"No class folders found under {dataset_dir}\")\n",
    "    return names\n",
    "\n",
    "def segment_image_inverted(arr: np.ndarray, threshold: float = SEGMENTATION_THRESHOLD) -> np.ndarray:\n",
    "    \"\"\"Apply INVERTED segmentation by setting pixel values ABOVE threshold to zero.\"\"\"\n",
    "    segmented = arr.copy()\n",
    "    mask = arr >= threshold\n",
    "    segmented[mask] = 0.0\n",
    "    return segmented\n",
    "\n",
    "def process_image(im: Image.Image) -> np.ndarray:\n",
    "    \"\"\"Apply image processing steps to a PIL Image - GRAYSCALE VERSION.\"\"\"\n",
    "    # Resize to target size\n",
    "    im = im.resize((IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    im = im.convert('L')\n",
    "    \n",
    "    # Optional preprocessing steps (uncomment as needed)\n",
    "    # im = ImageOps.equalize(im)\n",
    "    # im = ImageOps.autocontrast(im)\n",
    "    # im = im.filter(ImageFilter.MedianFilter(size=3))\n",
    "    \n",
    "    # Convert to numpy array and normalize\n",
    "    arr = np.asarray(im, dtype=np.float32) / 255.0\n",
    "    \n",
    "    # Apply inverted segmentation\n",
    "    arr = segment_image_inverted(arr, threshold=SEGMENTATION_THRESHOLD)\n",
    "    \n",
    "    # Add channel dimension for grayscale (H, W, 1)\n",
    "    arr = np.expand_dims(arr, axis=-1)\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def load_images(dataset_dir: str, class_names: List[str]):\n",
    "    \"\"\"Load all images from dataset directory.\"\"\"\n",
    "    X_list, y_list = [], []\n",
    "    \n",
    "    for cls_idx, cls_name in enumerate(class_names, start=1):\n",
    "        folder = Path(dataset_dir) / cls_name\n",
    "        files = sorted([p for p in folder.iterdir() if p.suffix.lower() in IMG_EXTS])\n",
    "        \n",
    "        if LIMIT_PER_CLASS is not None:\n",
    "            files = files[:LIMIT_PER_CLASS]\n",
    "        \n",
    "        print(f\"Loading {len(files)} images from {cls_name}...\")\n",
    "        \n",
    "        for p in files:\n",
    "            im = Image.open(p).convert(\"RGB\")\n",
    "            arr = process_image(im)\n",
    "            im.close()\n",
    "            X_list.append(arr)\n",
    "            y_list.append(cls_idx)\n",
    "    \n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list, dtype=np.int64)\n",
    "    return X, y\n",
    "\n",
    "def split_data(X, y):\n",
    "    \"\"\"Split data into train, validation, and test sets.\"\"\"\n",
    "    # First split: train vs (val + test)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, \n",
    "        test_size=(VAL_FRAC + TEST_FRAC), \n",
    "        stratify=y, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Second split: val vs test\n",
    "    val_ratio = VAL_FRAC / (VAL_FRAC + TEST_FRAC)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, \n",
    "        test_size=(1 - val_ratio), \n",
    "        stratify=y_temp, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "print(\"Data preparation functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names\n",
    "class_names = get_class_names(DATASET_DIR)\n",
    "print(f\"Classes found: {class_names}\")\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Load images\n",
    "print(\"\\nLoading images...\")\n",
    "X, y = load_images(DATASET_DIR, class_names)\n",
    "print(f\"Loaded: X shape = {X.shape}, y shape = {y.shape}\")\n",
    "print(f\"Note: Images are now grayscale with shape (H, W, 1)\")\n",
    "\n",
    "# Split data\n",
    "print(\"\\nSplitting data...\")\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y)\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Val:   {X_val.shape}\")\n",
    "print(f\"Test:  {X_test.shape}\")\n",
    "\n",
    "# Save processed data\n",
    "meta = {\"class_names\": class_names, \"img_size\": IMG_SIZE, \"grayscale\": True}\n",
    "np.savez_compressed(\n",
    "    OUT_NPZ,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_val=X_val, y_val=y_val,\n",
    "    X_test=X_test, y_test=y_test,\n",
    "    meta=json.dumps(meta)\n",
    ")\n",
    "print(f\"\\nSaved processed data to: {os.path.abspath(OUT_NPZ)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from each class\n",
    "fig, axes = plt.subplots(2, min(5, num_classes), figsize=(15, 6))\n",
    "if num_classes == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "for i in range(min(num_classes, 5)):\n",
    "    # Find first two images of this class\n",
    "    class_id = i + 1\n",
    "    idx = np.where(y_train == class_id)[0][:2]\n",
    "    \n",
    "    for j, img_idx in enumerate(idx):\n",
    "        ax = axes[j, i] if num_classes > 1 else axes[j]\n",
    "        ax.imshow(X_train[img_idx].squeeze(), cmap='gray')\n",
    "        ax.set_title(f\"{class_names[i]}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUT_DIR}/plots/sample_images.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. Visualize Image Processing Pipeline\n",
    "\n",
    "This section shows the effect of preprocessing: Original → Grayscale → Inverted Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a few original images to show processing steps\n",
    "def visualize_processing_pipeline(dataset_dir, class_names, num_samples=3):\n",
    "    \"\"\"Visualize the image processing pipeline: Original RGB → Grayscale → Inverted Segmentation.\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    sample_count = 0\n",
    "    for cls_idx, cls_name in enumerate(class_names):\n",
    "        if sample_count >= num_samples:\n",
    "            break\n",
    "        \n",
    "        folder = Path(dataset_dir) / cls_name\n",
    "        files = sorted([p for p in folder.iterdir() if p.suffix.lower() in IMG_EXTS])\n",
    "        \n",
    "        if not files:\n",
    "            continue\n",
    "        \n",
    "        # Take first image from this class\n",
    "        img_path = files[0]\n",
    "        \n",
    "        # Step 1: Original RGB\n",
    "        im_rgb = Image.open(img_path).convert(\"RGB\")\n",
    "        im_rgb_resized = im_rgb.resize((IMG_SIZE, IMG_SIZE))\n",
    "        arr_rgb = np.asarray(im_rgb_resized, dtype=np.float32) / 255.0\n",
    "        \n",
    "        # Step 2: Grayscale\n",
    "        im_gray = im_rgb_resized.convert('L')\n",
    "        arr_gray = np.asarray(im_gray, dtype=np.float32) / 255.0\n",
    "        \n",
    "        # Step 3: Apply inverted segmentation\n",
    "        arr_segmented = segment_image_inverted(arr_gray, threshold=SEGMENTATION_THRESHOLD)\n",
    "        \n",
    "        # Plot\n",
    "        axes[sample_count, 0].imshow(arr_rgb)\n",
    "        axes[sample_count, 0].set_title(f\"{cls_name}\\nOriginal RGB\")\n",
    "        axes[sample_count, 0].axis('off')\n",
    "        \n",
    "        axes[sample_count, 1].imshow(arr_gray, cmap='gray')\n",
    "        axes[sample_count, 1].set_title(f\"Grayscale\")\n",
    "        axes[sample_count, 1].axis('off')\n",
    "        \n",
    "        axes[sample_count, 2].imshow(arr_segmented, cmap='gray')\n",
    "        axes[sample_count, 2].set_title(f\"Inverted Segmentation\\n(threshold={SEGMENTATION_THRESHOLD})\")\n",
    "        axes[sample_count, 2].axis('off')\n",
    "        \n",
    "        im_rgb.close()\n",
    "        sample_count += 1\n",
    "    \n",
    "    plt.suptitle('Image Processing Pipeline (Grayscale + Inverted Segmentation)', fontsize=16, y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{OUT_DIR}/plots/processing_pipeline.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"✅ Processing pipeline visualization saved to: {OUT_DIR}/plots/processing_pipeline.png\")\n",
    "\n",
    "# Visualize processing for 3 sample images\n",
    "visualize_processing_pipeline(DATASET_DIR, class_names, num_samples=min(3, num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Building Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tiny_cnn(input_shape, num_classes):\n",
    "    \"\"\"Build a small CNN model.\"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPool2D(),\n",
    "        layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPool2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "def build_logreg_baseline(input_shape, num_classes):\n",
    "    \"\"\"Build a logistic regression baseline.\"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "print(\"Model building functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, model_name, epochs=EPOCHS, batch_size=BATCH_SIZE):\n",
    "    \"\"\"Train a model and plot training curves.\"\"\"\n",
    "    # Convert labels to categorical\n",
    "    y_train_cat = to_categorical(y_train - 1, num_classes=num_classes)\n",
    "    y_val_cat = to_categorical(y_val - 1, num_classes=num_classes)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train_cat,\n",
    "        validation_data=(X_val, y_val_cat),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[\"accuracy\"], label=\"Train\")\n",
    "    plt.plot(history.history[\"val_accuracy\"], label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"{model_name} - Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[\"loss\"], label=\"Train\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"{model_name} - Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{OUT_DIR}/plots/{model_name}_training.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Evaluate model and generate confusion matrix and classification report.\"\"\"\n",
    "    # Get predictions\n",
    "    y_true = (y_test - 1).astype(int)\n",
    "    y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\n{model_name} Test Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n",
    "    plt.title(f\"{model_name} - Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    \n",
    "    ticks = np.arange(num_classes)\n",
    "    plt.xticks(ticks, class_names, rotation=45, ha=\"right\")\n",
    "    plt.yticks(ticks, class_names)\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\")\n",
    "    \n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{OUT_DIR}/plots/{model_name}_cm.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, digits=4)\n",
    "    print(f\"\\n{model_name} Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Save report to file\n",
    "    with open(f\"{OUT_DIR}/reports/{model_name}_report.txt\", \"w\") as f:\n",
    "        f.write(f\"Test Accuracy: {acc:.4f}\\n\\n\")\n",
    "        f.write(report)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "print(\"Training and evaluation functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN model (note: input shape is now (IMG_SIZE, IMG_SIZE, 1) for grayscale)\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, 1)\n",
    "cnn_model = build_tiny_cnn(input_shape, num_classes)\n",
    "cnn_model.summary()\n",
    "\n",
    "# Train CNN\n",
    "cnn_history = train_model(cnn_model, X_train, y_train, X_val, y_val, \"tiny_cnn\")\n",
    "\n",
    "# Save model\n",
    "cnn_model.save(f\"{OUT_DIR}/models/tiny_cnn.keras\")\n",
    "print(f\"\\nCNN model saved to: {OUT_DIR}/models/tiny_cnn.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_accuracy = evaluate_model(cnn_model, X_test, y_test, \"tiny_cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build logistic regression model\n",
    "logreg_model = build_logreg_baseline(input_shape, num_classes)\n",
    "logreg_model.summary()\n",
    "\n",
    "# Train logistic regression\n",
    "logreg_history = train_model(logreg_model, X_train, y_train, X_val, y_val, \"logreg\")\n",
    "\n",
    "# Save model\n",
    "logreg_model.save(f\"{OUT_DIR}/models/logreg.keras\")\n",
    "print(f\"\\nLogistic regression model saved to: {OUT_DIR}/models/logreg.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluate Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_accuracy = evaluate_model(logreg_model, X_test, y_test, \"logreg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model accuracies\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Tiny CNN Test Accuracy:        {cnn_accuracy:.4f}\")\n",
    "print(f\"Logistic Regression Accuracy:  {logreg_accuracy:.4f}\")\n",
    "print(f\"Improvement:                   {(cnn_accuracy - logreg_accuracy):.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Bar plot comparison\n",
    "plt.figure(figsize=(8, 5))\n",
    "models = ['Logistic Regression', 'Tiny CNN']\n",
    "accuracies = [logreg_accuracy, cnn_accuracy]\n",
    "colors = ['#FF6B6B', '#4ECDC4']\n",
    "\n",
    "bars = plt.bar(models, accuracies, color=colors, alpha=0.8, edgecolor='black')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Model Comparison (Grayscale + Inverted Segmentation)')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{acc:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUT_DIR}/plots/model_comparison.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary\n",
    "\n",
    "### Workflow Complete!\n",
    "\n",
    "This notebook has:\n",
    "1. ✅ Loaded and preprocessed images from the dataset\n",
    "2. ✅ **Converted images to grayscale to reduce training time**\n",
    "3. ✅ **Applied inverted segmentation (pixels ABOVE threshold set to zero)**\n",
    "4. ✅ Split data into train/validation/test sets\n",
    "5. ✅ Built and trained a CNN model\n",
    "6. ✅ Built and trained a logistic regression baseline\n",
    "7. ✅ Evaluated both models on the test set\n",
    "8. ✅ Generated confusion matrices and classification reports\n",
    "9. ✅ Saved all models, plots, and reports\n",
    "\n",
    "### Key Differences from RGB Version:\n",
    "- **Grayscale**: Images converted to single channel (reduces parameters by ~3x)\n",
    "- **Inverted Segmentation**: Pixels ABOVE threshold are zeroed (vs BELOW in RGB version)\n",
    "- **Faster Training**: Grayscale images require less computation\n",
    "\n",
    "### Output Files:\n",
    "- **Models**: `./artifacts_grey/models/` (tiny_cnn.keras, logreg.keras)\n",
    "- **Plots**: `./artifacts_grey/plots/` (training curves, confusion matrices)\n",
    "- **Reports**: `./artifacts_grey/reports/` (classification reports)\n",
    "- **Data**: `./artifacts_grey/rbc_data_grey.npz` (preprocessed dataset)\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different preprocessing techniques (uncomment in `process_image()`)\n",
    "- Adjust `SEGMENTATION_THRESHOLD` for better cell isolation\n",
    "- Try different model architectures\n",
    "- Increase `EPOCHS` for potentially better performance\n",
    "- Add data augmentation for improved generalization\n",
    "- Compare performance with RGB version from RBC_Complete_Workflow.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
